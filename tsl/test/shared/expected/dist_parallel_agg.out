-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Test that for parallel-safe aggregate function a parallel plan is generated
-- on data nodes, and for unsafe it is not. We use a manually created safe
-- function and not a builtin one, to check that we can in fact create a
-- function that is parallelized, to prevent a false negative (i.e. it's not
-- parallelized, but for a different reason, not because it's unsafe).
-- Create a relatively big table on one data node to test parallel plans and
-- avoid flakiness.
create table metrics_dist1(like metrics_dist);
select table_name from create_distributed_hypertable('metrics_dist1', 'time', 'device_id',
    data_nodes => '{"data_node_1"}');
WARNING:  only one data node was assigned to the hypertable
  table_name   
 metrics_dist1
(1 row)

insert into metrics_dist1 select * from metrics_dist order by metrics_dist limit 20000;
-- Start transaction in order to keep same connection
-- during the test and avoid connection cache invalidations
begin;
\set safe 'create or replace aggregate ts_debug_shippable_safe_count(*) (sfunc = int8inc, combinefunc=int8pl, stype = bigint, initcond = 0, parallel = safe);'
\set unsafe 'create or replace aggregate ts_debug_shippable_unsafe_count(*) (sfunc = int8inc, combinefunc=int8pl, stype = bigint, initcond = 0, parallel = unsafe);'
:safe
call distributed_exec(:'safe');
:unsafe
call distributed_exec(:'unsafe');
call distributed_exec($$ set parallel_tuple_cost = 0; $$);
call distributed_exec($$ set parallel_setup_cost = 0; $$);
call distributed_exec($$ set max_parallel_workers_per_gather = 1; $$);
set timescaledb.enable_remote_explain = 1;
set enable_partitionwise_aggregate = 1;
\set analyze 'explain (analyze, verbose, costs off, timing off, summary off)'
:analyze
select count(*) from metrics_dist1;
QUERY PLAN
 Custom Scan (DataNodeScan) (actual rows=1 loops=1)
   Output: (count(*))
   Relations: Aggregate on (public.metrics_dist1)
   Data node: data_node_1
   Fetcher Type: COPY
   Chunks: _dist_hyper_X_X_chunk, _dist_hyper_X_X_chunk
   Remote SQL: SELECT count(*) FROM public.metrics_dist1 WHERE _timescaledb_functions.chunks_in(public.metrics_dist1.*, ARRAY[..])
   Remote EXPLAIN: 
     Finalize Aggregate (actual rows=1 loops=1)
       Output: count(*)
       ->  Gather (actual rows=2 loops=1)
             Output: (PARTIAL count(*))
             Workers Planned: 1
             Workers Launched: 1
             ->  Partial Aggregate (actual rows=1 loops=2)
                   Output: PARTIAL count(*)
                   Worker 0: actual rows=1 loops=1
                   ->  Parallel Append (actual rows=10000 loops=2)
                         Worker 0: actual rows=0 loops=1
                         ->  Parallel Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=17990 loops=1)
                         ->  Parallel Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=2010 loops=1)
 
(22 rows)

:analyze
select ts_debug_shippable_safe_count(*) from metrics_dist1;
QUERY PLAN
 Custom Scan (DataNodeScan) (actual rows=1 loops=1)
   Output: (ts_debug_shippable_safe_count(*))
   Relations: Aggregate on (public.metrics_dist1)
   Data node: data_node_1
   Fetcher Type: COPY
   Chunks: _dist_hyper_X_X_chunk, _dist_hyper_X_X_chunk
   Remote SQL: SELECT public.ts_debug_shippable_safe_count(*) FROM public.metrics_dist1 WHERE _timescaledb_functions.chunks_in(public.metrics_dist1.*, ARRAY[..])
   Remote EXPLAIN: 
     Finalize Aggregate (actual rows=1 loops=1)
       Output: public.ts_debug_shippable_safe_count(*)
       ->  Gather (actual rows=2 loops=1)
             Output: (PARTIAL public.ts_debug_shippable_safe_count(*))
             Workers Planned: 1
             Workers Launched: 1
             ->  Partial Aggregate (actual rows=1 loops=2)
                   Output: PARTIAL public.ts_debug_shippable_safe_count(*)
                   Worker 0: actual rows=1 loops=1
                   ->  Parallel Append (actual rows=10000 loops=2)
                         Worker 0: actual rows=0 loops=1
                         ->  Parallel Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=17990 loops=1)
                         ->  Parallel Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=2010 loops=1)
 
(22 rows)

:analyze
select ts_debug_shippable_unsafe_count(*) from metrics_dist1;
QUERY PLAN
 Custom Scan (DataNodeScan) (actual rows=1 loops=1)
   Output: (ts_debug_shippable_unsafe_count(*))
   Relations: Aggregate on (public.metrics_dist1)
   Data node: data_node_1
   Fetcher Type: COPY
   Chunks: _dist_hyper_X_X_chunk, _dist_hyper_X_X_chunk
   Remote SQL: SELECT public.ts_debug_shippable_unsafe_count(*) FROM public.metrics_dist1 WHERE _timescaledb_functions.chunks_in(public.metrics_dist1.*, ARRAY[..])
   Remote EXPLAIN: 
     Aggregate (actual rows=1 loops=1)
       Output: public.ts_debug_shippable_unsafe_count(*)
       ->  Append (actual rows=20000 loops=1)
             ->  Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=17990 loops=1)
             ->  Seq Scan on _timescaledb_internal._dist_hyper_X_X_chunk (actual rows=2010 loops=1)
 
(14 rows)

commit;
